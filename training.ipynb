{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:albumentations.check_version:Error fetching version info\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1286, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1332, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1281, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1041, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 979, in send\n",
      "    self.connect()\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1458, in connect\n",
      "    self.sock = self._context.wrap_socket(self.sock,\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 1108, in _create\n",
      "    self.do_handshake()\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 1379, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\check_version.py\", line 29, in fetch_version_info\n",
      "    with opener.open(url, timeout=2) as response:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:989: The handshake operation timed out>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.utils import save_checkpoint, load_checkpoint, save_some_examples\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import config\n",
    "from DataSet.dataset import Satellite2Map_Data\n",
    "from pix2pix.Generator import Generator\n",
    "from pix2pix.Discriminator import Discriminator\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "Gen_loss = []\n",
    "Dis_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(netG: Generator, netD: Discriminator, train_dl, OptimizerG: optim.Adam, OptimizerD: optim.Adam, L1_loss: nn.L1Loss, BCE_loss: nn.BCEWithLogitsLoss):\n",
    "    loop = tqdm(train_dl, dynamic_ncols= True)\n",
    "    for idx, (x,y) in enumerate(loop):\n",
    "        x = x.to(config.DEVICE)\n",
    "        y = y.to(config.DEVICE)\n",
    "        y = y.permute(0,3,1,2)\n",
    "\n",
    "        # print(idx)\n",
    "\n",
    "        # Train Discriminator\n",
    "        y_fake = netG(x)\n",
    "        d_real = netD(x,y)\n",
    "        d_real_loss = BCE_loss(d_real, torch.ones_like(d_real))\n",
    "        d_fake = netD(x,y_fake.detach())\n",
    "        d_fake_loss = BCE_loss(d_fake, torch.zeros_like(d_fake))\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        \n",
    "        netD.zero_grad()\n",
    "        Dis_loss.append(d_loss.item())\n",
    "        d_loss.backward()\n",
    "        OptimizerD.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        d_fake = netD(x,y_fake)\n",
    "        g_fake_loss = BCE_loss(d_fake, torch.ones_like(d_fake))\n",
    "        l1 = L1_loss(y_fake,y) * config.L1_LAMBDA\n",
    "        g_loss = g_fake_loss + l1\n",
    "        \n",
    "        OptimizerG.zero_grad()\n",
    "        Gen_loss.append(g_loss.item())\n",
    "        g_loss.backward()\n",
    "        OptimizerG.step()\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            loop.set_postfix(\n",
    "                d_real = torch.sigmoid(d_real).mean().item(),\n",
    "                d_fake = torch.sigmoid(d_fake).mean().item()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1fad4253dc4d059be04c9a388e38e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    netD = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "    netG = Generator(in_channels=3).to(config.DEVICE)\n",
    "    optimizerD = torch.optim.Adam(netD.parameters(), lr = config.LEARNING_RATE, betas=(config.BETA1, 0.999))\n",
    "    optimizerG = torch.optim.Adam(netG.parameters(), lr = config.LEARNING_RATE, betas=(config.BETA1, 0.999))\n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "    \n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN, netG, optimizerG, config.LEARNING_RATE\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_DISC, netD, optimizerD, config.LEARNING_RATE\n",
    "        )\n",
    "    \n",
    "    train_dataset = Satellite2Map_Data(root=config.TRAIN_DIR)\n",
    "    train_dl = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
    "    val_dataset = Satellite2Map_Data(root=config.VAL_DIR)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        train(\n",
    "            netG, netD,train_dl,optimizerG,optimizerD,l1_loss,bce_loss\n",
    "        )\n",
    "        if config.SAVE_MODEL and epoch % 50 == 0:\n",
    "            save_checkpoint(netG, optimizerG, filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_GEN}\")\n",
    "            save_checkpoint(netD, optimizerD, filename=f\"./checkpoints/{epoch}_{config.CHECKPOINT_DISC}\")\n",
    "        if epoch % 2 == 0:\n",
    "            print(\"save example\")\n",
    "            try:\n",
    "                save_some_examples(netG,val_dl,epoch,folder=\"evaluation\")\n",
    "            except Exception as e:\n",
    "                print(f\"Something went wrong with epoch {epoch}: {e}\")\n",
    "\n",
    "        print(\"Epoch : \",epoch, \"Gen Loss : \",Gen_loss[epoch], \"Disc Loss : \",Dis_loss[epoch])\n",
    "        save_checkpoint(netG, optimizerG, filename= f\"./checkpoints/final_{config.CHECKPOINT_GEN}\")\n",
    "        save_checkpoint(netD, optimizerD, filename=f\"./checkpoints/final_{config.CHECKPOINT_DISC}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
