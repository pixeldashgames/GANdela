{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:albumentations.check_version:Error fetching version info\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1286, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1332, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1281, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1041, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 979, in send\n",
      "    self.connect()\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1458, in connect\n",
      "    self.sock = self._context.wrap_socket(self.sock,\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 1108, in _create\n",
      "    self.do_handshake()\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 1379, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\check_version.py\", line 29, in fetch_version_info\n",
      "    with opener.open(url, timeout=2) as response:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alfredo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:989: The handshake operation timed out>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.utils import save_checkpoint, load_checkpoint, save_some_examples\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import config\n",
    "from DataSet.dataset import Satellite2Map_Data\n",
    "from pix2pix.Generator import Generator\n",
    "from pix2pix.Discriminator import Discriminator\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "Gen_loss = []\n",
    "Dis_loss = []\n",
    "step_ahead = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(netG: Generator, netD: Discriminator, train_dl, OptimizerG: optim.Adam, OptimizerD: optim.Adam, gen_loss, dis_loss):\n",
    "    loop = tqdm(train_dl, dynamic_ncols=True)\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x = x.to(config.DEVICE)\n",
    "        y = y.to(config.DEVICE)\n",
    "        y = y.permute(0,3,1,2).float()\n",
    "\n",
    "        # Train Discriminator\n",
    "        y_fake = netG(x).float()\n",
    "        d_real = netD(x, y)\n",
    "        d_real_loss = dis_loss(d_real, torch.ones_like(d_real))\n",
    "        d_fake = netD(x, y_fake.detach())\n",
    "        d_fake_loss = dis_loss(d_fake, torch.zeros_like(d_fake))\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        netD.zero_grad()\n",
    "        Dis_loss.append(d_loss.item())\n",
    "        d_loss.backward()\n",
    "        OptimizerD.step()\n",
    "\n",
    "        # Train Generator\n",
    "        d_fake = netD(x, y_fake)\n",
    "        g_fake_loss = gen_loss(d_fake, torch.ones_like(d_fake)) \n",
    "        loss = gen_loss(y_fake, y) # * config.L1_LAMBDA\n",
    "        g_loss = (g_fake_loss + loss)/2\n",
    "\n",
    "\n",
    "        Gen_loss.append(g_loss.item())\n",
    "        g_loss.backward()\n",
    "        OptimizerG.step()\n",
    "\n",
    "        for _ in range(step_ahead):\n",
    "            OptimizerG.zero_grad()\n",
    "            y_fake = netG(x).float()\n",
    "            d_fake = netD(x, y_fake)\n",
    "            g_fake_loss = gen_loss(d_fake, torch.ones_like(d_fake))\n",
    "            loss = gen_loss(y_fake, y) # * config.L1_LAMBDA\n",
    "\n",
    "            g_loss = (g_fake_loss + loss)/2\n",
    "            Gen_loss.append(g_loss.item())\n",
    "            g_loss.backward()\n",
    "            OptimizerG.step()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            loop.set_postfix(\n",
    "                d_real=torch.sigmoid(d_real).mean().item(),\n",
    "                d_fake=torch.sigmoid(d_fake).mean().item(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61b0eea1c3f4547b3d0dcbfdf4cd596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save example\n",
      "Epoch : 0  Gen Loss : 4950.72607421875 Disc Loss : 0.6405190229415894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a65f4e3e0b94ad3bdd3481d09891b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1  Gen Loss : 5117.193359375 Disc Loss : 0.6624758243560791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece9a7aa10e24ed2a847b3dfd5af567f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save example\n",
      "Epoch : 2  Gen Loss : 4450.1943359375 Disc Loss : 0.47364386916160583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9608c762c12c4dd4897d32e3be858cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3  Gen Loss : 4071.05908203125 Disc Loss : 0.41964191198349\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564fe22c2f59493db0c452a563603d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save example\n",
      "Epoch : 4  Gen Loss : 6354.8623046875 Disc Loss : 0.3669929504394531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e9ca472ffd4bbab283b4b280524bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5  Gen Loss : 4814.03369140625 Disc Loss : 0.2540337145328522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f7f0d8fcfe47c58cf35fd5b7413ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    start = 0\n",
    "    netD = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "    netG = Generator(in_channels=3).to(config.DEVICE)\n",
    "    optimizerD = torch.optim.Adam(netD.parameters(), lr = config.LEARNING_RATE, betas=(config.BETA1, 0.999))\n",
    "    optimizerG = torch.optim.Adam(netG.parameters(), lr = config.LEARNING_RATE, betas=(config.BETA1, 0.999))\n",
    "    dis_loss = nn.MSELoss()\n",
    "    gen_loss = nn.MSELoss()\n",
    "    \n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN, start-1, netG, optimizerG, config.LEARNING_RATE\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_DISC, start-1, netD, optimizerD, config.LEARNING_RATE\n",
    "        )\n",
    "    \n",
    "    train_dataset = Satellite2Map_Data(root=config.TRAIN_DIR)\n",
    "    train_dl = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    val_dataset = Satellite2Map_Data(root=config.VAL_DIR)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    \n",
    "    for epoch in range(start, config.NUM_EPOCHS):\n",
    "        train(\n",
    "            netG, netD,train_dl,optimizerG,optimizerD,gen_loss,dis_loss\n",
    "        )\n",
    "        if config.SAVE_MODEL and epoch % 10 == 0 and epoch > 0:\n",
    "            save_checkpoint(netG, optimizerG, epoch, Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_GEN}\")\n",
    "            save_checkpoint(netD, optimizerD, epoch, Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_DISC}\")\n",
    "        if epoch % 2 == 0 :\n",
    "            print(\"save example\")\n",
    "            try:\n",
    "                save_some_examples(netG,val_dl,epoch,folder=\"evaluation\")\n",
    "            except Exception as e:\n",
    "                print(f\"Something went wrong with epoch {epoch}: {e}\")\n",
    "\n",
    "        print(\"Epoch :\",epoch, \" Gen Loss :\",Gen_loss[-1], \"Disc Loss :\",Dis_loss[-1])\n",
    "    save_checkpoint(netG, optimizerG, \"final\", Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_GEN}\")\n",
    "    save_checkpoint(netD, optimizerD, \"final\", Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_DISC}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
