{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# !pip install --upgrade albumentations\n",
    "from utils import save_checkpoint, load_checkpoint, save_some_examples\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import config\n",
    "from DataSet.dataset import Satellite2Map_Data\n",
    "from pix2pix.Generator import Generator\n",
    "from pix2pix.Discriminator import Discriminator\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "Gen_loss = []\n",
    "Dis_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(netG: Generator, netD: Discriminator, train_dl, OptimizerG: optim.Adam, OptimizerD: optim.Adam, gen_loss, dis_loss,scheduler_G, scheduler_D, step_ahead = 0):\n",
    "    loop = tqdm(train_dl, dynamic_ncols=True)\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x = x.to(config.DEVICE).float()\n",
    "        y = y.to(config.DEVICE).float()\n",
    "        \n",
    "        # Train Discriminator\n",
    "        y_fake = netG(x).float()\n",
    "        d_real = netD(x, y)\n",
    "        d_real_loss = dis_loss(d_real, torch.ones_like(d_real))\n",
    "        d_fake = netD(x, y_fake.detach())\n",
    "        d_fake_loss = dis_loss(d_fake, torch.zeros_like(d_fake))\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        netD.zero_grad()\n",
    "        Dis_loss.append(d_loss.item())\n",
    "        d_loss.backward()\n",
    "        OptimizerD.step()\n",
    "\n",
    "        # Train Generator\n",
    "        d_fake = netD(x, y_fake)\n",
    "        g_fake_loss = gen_loss(d_fake, torch.ones_like(d_fake))\n",
    "        loss = gen_loss(y_fake, y)  # * config.L1_LAMBDA\n",
    "        g_loss = (g_fake_loss + loss) / 2\n",
    "\n",
    "        Gen_loss.append(g_loss.item())\n",
    "        g_loss.backward()\n",
    "        OptimizerG.step()\n",
    "\n",
    "        for _ in range(step_ahead):\n",
    "            OptimizerG.zero_grad()\n",
    "            y_fake = netG(x).float()\n",
    "            d_fake = netD(x, y_fake)\n",
    "            g_fake_loss = gen_loss(d_fake, torch.ones_like(d_fake))\n",
    "            loss = gen_loss(y_fake, y)  # * config.L1_LAMBDA\n",
    "\n",
    "            g_loss = (g_fake_loss + loss) / 2\n",
    "            Gen_loss.append(g_loss.item())\n",
    "            g_loss.backward()\n",
    "            OptimizerG.step()\n",
    "        \n",
    "        scheduler_G.step(g_loss.item())  \n",
    "        scheduler_D.step(d_loss.item())  \n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            loop.set_postfix(\n",
    "                d_real=torch.sigmoid(d_real).mean().item(),\n",
    "                d_fake=torch.sigmoid(d_fake).mean().item(),\n",
    "            )\n",
    "    print(\"d_real: \" + str(torch.sigmoid(d_real).mean().item()))\n",
    "    print(\"d_fake: \" + str(torch.sigmoid(d_fake).mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start = 231\n",
    "    rgb_on = False\n",
    "    channels = 3 if rgb_on else 1\n",
    "\n",
    "    netD = Discriminator(in_channels=channels).to(config.DEVICE)\n",
    "    netG = Generator(in_channels=channels).to(config.DEVICE)\n",
    "    optimizerD = torch.optim.Adam(\n",
    "        netD.parameters(), lr=config.LEARNING_RATE_DISC, betas=(config.BETA1, 0.999)\n",
    "    )\n",
    "    optimizerG = torch.optim.Adam(\n",
    "        netG.parameters(), lr=config.LEARNING_RATE_GEN, betas=(config.BETA1, 0.999)\n",
    "    )\n",
    "    gen_loss = nn.MSELoss()\n",
    "    dis_loss = nn.MSELoss()\n",
    "\n",
    "    \n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN, start-1, netG, optimizerG, config.LEARNING_RATE_GEN\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_DISC, start-1, netD, optimizerD, config.LEARNING_RATE_DISC\n",
    "        )\n",
    "    \n",
    "    train_dataset = Satellite2Map_Data(root=config.TRAIN_DIR, rgb_on=rgb_on)\n",
    "    train_dl = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    val_dataset = Satellite2Map_Data(root=config.VAL_DIR, rgb_on=rgb_on)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    \n",
    "    for epoch in range(start, config.NUM_EPOCHS):\n",
    "        train(\n",
    "            netG, netD,train_dl,optimizerG,optimizerD,gen_loss,dis_loss, step_ahead=2\n",
    "        )\n",
    "        if config.SAVE_MODEL and epoch % 10 == 0 and epoch > 0:\n",
    "            save_checkpoint(netG, optimizerG, epoch, Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_GEN}\")\n",
    "            save_checkpoint(netD, optimizerD, epoch, Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_DISC}\")\n",
    "        if epoch % 10 == 0 :\n",
    "            print(\"save example\")\n",
    "            try:\n",
    "                save_some_examples(netG,val_dl,epoch,folder=\"evaluation\")\n",
    "            except Exception as e:\n",
    "                print(f\"Something went wrong saving with epoch {epoch}: {e}\")\n",
    "\n",
    "        print(\"Epoch :\",epoch, \" Gen Loss :\",Gen_loss[-1], \"Disc Loss :\",Dis_loss[-1])\n",
    "    save_checkpoint(netG, optimizerG, \"final\", Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_GEN}\")\n",
    "    save_checkpoint(netD, optimizerD, \"final\", Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_DISC}\")\n",
    "    print(\"save example\")\n",
    "    try:\n",
    "        save_some_examples(netG,val_dl,config.NUM_EPOCHS,folder=\"evaluation\")\n",
    "    except Exception as e:\n",
    "        print(f\"Something went wrong with the last epoch\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from DataSet.dataset import Satellite2Map_Data\n",
    "from torch.utils.data import DataLoader\n",
    "import config\n",
    "\n",
    "def get_folder_names(folder_path):\n",
    "  folder_names = []\n",
    "  for item in os.listdir(folder_path):\n",
    "    item_path = os.path.join(folder_path, item)\n",
    "    if os.path.isdir(item_path):\n",
    "      folder_names.append(item)\n",
    "  return folder_names\n",
    "\n",
    "folder_path = \"./versions (Gen-Disc)\"\n",
    "folder_names = get_folder_names(folder_path)\n",
    "\n",
    "val_dataset = Satellite2Map_Data(root=config.VAL_DIR, rgb_on=False)\n",
    "val_dl = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "\n",
    "tests = []\n",
    "\n",
    "for i, batch in enumerate(val_dl):\n",
    "    if i >= 1:  # Stop after collecting 1 batch\n",
    "        break\n",
    "    tests = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is L1 with BCEwithLogits with a rmse of 0.5253028869628906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils import save_matrix\n",
    "import config\n",
    "import numpy as np\n",
    "import torch\n",
    "from pix2pix.Generator import Generator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model,folder_path, lr):\n",
    "  checkpoint = torch.load(\n",
    "    f\"{folder_path}/399_{config.CHECKPOINT_GEN}\", map_location=config.DEVICE\n",
    "  )\n",
    "  model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "def save_some_examples(gen, val_loader, epoch, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    x, y = next(iter(val_loader))\n",
    "    x, y = x.to(config.DEVICE).float(), y.to(config.DEVICE).float()\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        y_fake = gen(x)\n",
    "        save_matrix(y_fake, folder + f\"/y_gen_{epoch}.pkl\")\n",
    "        save_matrix(y, folder + f\"/label_{epoch}.pkl\")\n",
    "    gen.train()\n",
    "\n",
    "def calculate_rmse(matrix1, matrix2):\n",
    "\n",
    "  # Ensure matrices have the same shape\n",
    "  if matrix1.shape != matrix2.shape:\n",
    "    raise ValueError(\"Matrices must have the same shape.\")\n",
    "\n",
    "  squared_differences = (matrix1 - matrix2) ** 2\n",
    "  mean_squared_error = np.mean(squared_differences)\n",
    "  rmse = np.sqrt(mean_squared_error)\n",
    "\n",
    "  return rmse\n",
    "\n",
    "\n",
    "model_error = []\n",
    "for folder in folder_names:\n",
    "    netG = Generator(in_channels=1).to(config.DEVICE)\n",
    "    \n",
    "    load_model(netG,f\"{folder_path}/{folder}\",config.LEARNING_RATE_GEN)\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for i in range(len(tests[0])):\n",
    "      x, y = tests[0][i], tests[1][i]\n",
    "      x, y = x.to(config.DEVICE).float().unsqueeze(1), y.to(config.DEVICE).float().unsqueeze(1)\n",
    "      netG.eval()\n",
    "      with torch.no_grad():\n",
    "          y_fake = netG(x)\n",
    "      y_fake = y_fake.cpu().detach().numpy().squeeze()\n",
    "      y = y.cpu().detach().numpy().squeeze()\n",
    "\n",
    "      errors.append(calculate_rmse(y,y_fake))\n",
    "    \n",
    "    model_error.append(np.mean(errors))\n",
    "\n",
    "indexed_list = list(enumerate(model_error))\n",
    "sorted_list = sorted(indexed_list, key= lambda x: x[1])\n",
    "\n",
    "print(f\"The best model is {folder_names[sorted_list[0][0]]} with a rmse of {sorted_list[0][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "def main():\n",
    "    start = 0\n",
    "    rgb_on = False\n",
    "    channels = 3 if rgb_on else 1\n",
    "\n",
    "    batch_size = [16,32]\n",
    "\n",
    "    netD = Discriminator(in_channels=channels).to(config.DEVICE)\n",
    "    netG = Generator(in_channels=channels).to(config.DEVICE)\n",
    "    \n",
    "    optimizerD = torch.optim.Adam(\n",
    "        netD.parameters(), lr=0.001, betas=(config.BETA1, 0.999)\n",
    "    )\n",
    "    optimizerG = torch.optim.Adam(\n",
    "        netG.parameters(), lr=0.001, betas=(config.BETA1, 0.999)\n",
    "    )\n",
    "\n",
    "    scheduler_G = ReduceLROnPlateau(optimizerG, 'min', factor=0.5, patience=5, verbose=True)\n",
    "    scheduler_D = ReduceLROnPlateau(optimizerD, 'min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    gen_loss = nn.L1Loss()\n",
    "    dis_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    \n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN, start-1, netG, optimizerG, config.LEARNING_RATE_GEN\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_DISC, start-1, netD, optimizerD, config.LEARNING_RATE_DISC\n",
    "        )\n",
    "    \n",
    "    train_dataset = Satellite2Map_Data(root=config.TRAIN_DIR, rgb_on=rgb_on)\n",
    "    train_dl = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    val_dataset = Satellite2Map_Data(root=config.VAL_DIR, rgb_on=rgb_on)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    \n",
    "    for epoch in range(start, config.NUM_EPOCHS):\n",
    "        train(\n",
    "            netG, netD, train_dl, optimizerG, optimizerD, gen_loss, dis_loss, \n",
    "            scheduler_G, scheduler_D, step_ahead=2\n",
    "        )\n",
    "        if config.SAVE_MODEL and epoch % 10 == 0 and epoch > 0:\n",
    "            save_checkpoint(netG, optimizerG, epoch, Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_GEN}\")\n",
    "            save_checkpoint(netD, optimizerD, epoch, Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_DISC}\")\n",
    "        if epoch % 10 == 0 :\n",
    "            print(\"save example\")\n",
    "            try:\n",
    "                save_some_examples(netG,val_dl,epoch,folder=\"evaluation\")\n",
    "            except Exception as e:\n",
    "                print(f\"Something went wrong saving with epoch {epoch}: {e}\")\n",
    "\n",
    "        print(\"Epoch :\",epoch, \" Gen Loss :\",Gen_loss[-1], \"Disc Loss :\",Dis_loss[-1])\n",
    "    save_checkpoint(netG, optimizerG, \"final\", Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_GEN}\")\n",
    "    save_checkpoint(netD, optimizerD, \"final\", Gen_loss[-1], Dis_loss[-1], filename= f\"./checkpoints/{epoch}_{config.CHECKPOINT_DISC}\")\n",
    "    print(\"save example\")\n",
    "    try:\n",
    "        save_some_examples(netG,val_dl,config.NUM_EPOCHS,folder=\"evaluation\")\n",
    "    except Exception as e:\n",
    "        print(f\"Something went wrong with the last epoch\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
